# ***************
# a)
library(datarium)
data("marketing")
summary(marketing)
# b)
head(marketing, 4)
marketing$youtube <- as.numeric(marketing$youtube)
marketing$facebook <- as.numeric(marketing$facebook)
marketing$newspaper <- as.numeric(marketing$newspaper)
marketing$sales <- as.numeric(marketing$sales)
cor(marketing)[4, 1:3]
summary(marketing)
hist(marketing$sales, main = "histograma da variável objeto", xlab = "valor de vendas")
install.packages("datarium")
# ***************
# exercise 01
# ***************
# a)
library(datarium)
data("marketing")
summary(marketing)
# b)
head(marketing, 4)
marketing$youtube <- as.numeric(marketing$youtube)
marketing$facebook <- as.numeric(marketing$facebook)
marketing$newspaper <- as.numeric(marketing$newspaper)
marketing$sales <- as.numeric(marketing$sales)
cor(marketing)[4, 1:3]
summary(marketing)
hist(marketing$sales, main = "histograma da variável objeto", xlab = "valor de vendas")
# Libraries
library(rpart)
library(rpart.plot)
library(neuralnet)
# Variáveis globais
MAE <- function(method, d) {
mae <- mean(abs(d))
cat("(", method, ") MAE: ", mae)
}
RMSE <- function(method, d) {
rmse <- sqrt(mean(d^2))
cat("(", method, ") RMSE: ", rmse)
}
################################################## REGRESSÃO ##################################################
# Exercício 1 --------------------------------------------------
data <- read.csv("")
str(data)
head(data)
dimension <- dim(data)
cat("Dimensão\nLinhas: ", dimension[1], "\t Colunas: ", dimension[2])
summary(data)
numberRows <- nrow(data)
# Exercício 2 --------------------------------------------------
# Variáveis
#
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, ]
data.test <- data[-index, ]
library(readxl)
data <- read_excel("D:/01. Work/01. University - ISEP (MEI)/01. Pré-Requisitos/06. Análise de Dados em Informática/Trabalho em Grupo ANADI/Iteration 02/countryagregatedata.xlsx")
View(data)
# Libraries
library(rpart)
library(rpart.plot)
library(neuralnet)
# Variáveis globais
MAE <- function(method, d) {
mae <- mean(abs(d))
cat("(", method, ") MAE: ", mae)
}
RMSE <- function(method, d) {
rmse <- sqrt(mean(d^2))
cat("(", method, ") RMSE: ", rmse)
}
################################################## REGRESSÃO ##################################################
# Exercício 1 --------------------------------------------------
data <- read.csv("")
str(data)
head(data)
dimension <- dim(data)
cat("Dimensão\nLinhas: ", dimension[1], "\t Colunas: ", dimension[2])
summary(data)
numberRows <- nrow(data)
# Exercício 2 --------------------------------------------------
# Variáveis
# Exercício 3 --------------------------------------------------
# Variáveis
# Divisão dos dados em dois subconjuntos - treino e teste - segundo o critério holdout (70% treino/30% teste)
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, ]
data.test <- data[-index, ]
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, ]
data.test <- data[-index, ]
# Alínea a)
slr.model <- lm(total_deaths ~ new_cases, data = data.train)
slr.model
summary(slr.model)
plot(data.train$new_cases, data.train$total_deaths, pch = 20)
abline(slr.model$coefficients[1], slr.model$coefficients[2], col = "red")
# Alínea b)
plot(data.train$new_cases, data.train$total_deaths, pch = 20,
xlab = "Novos Casos",
ylab = "Total de Mortes",
main = "Diagrama de Dispersão e Reta de Regressão")
abline(slr.model$coefficients[1], slr.model$coefficients[2], col = "red")
slr.pred <- predict(slr.model, data.test)
d <- data.test$total_deaths - slr.pred
# Erro Médio Absoluto
MAE("Regressão Linear", d);
# Raiz Quadrada do Erro Médio
RMSE("Regressão Linear", d);
#Exercicio 1 - Ficha TP6 Arvores de Decisão
#Ana Madureira
#Pretende-se determinar a qual das duas classes (benigna ou maligna) o tumor pertence:
#  a) Comece por carregar o dataset ”BreastCancer” da biblioteca “mlbench” para o ambiente
# do R. Verifique a sua dimensão e obtenha um sumário dos dados;
library(rpart)
library(mlbench)
# Será utilizado o dataset Wisconsin Breast Cancer
data(BreastCancer)
dim(BreastCancer)
View(BreastCancer)
###[1] 699  11
### levels(BreastCancer$Class)
###[1] "benign"    "malignant"
head(BreastCancer)
summary(BreastCancer)
#b) Usando os gráficos apropriados, analise os vários atributos do conjunto de dados;
library(corrplot)
BreastCancer$Cl.thickness <- as.numeric(BreastCancer$Cl.thickness)
BreastCancer$Cell.size <- as.numeric(BreastCancer$Cell.size)
BreastCancer$Cell.shape <- as.numeric(BreastCancer$Cell.shape)
BreastCancer$Marg.adhesion <- as.numeric(BreastCancer$Marg.adhesion)
BreastCancer$Epith.c.size <- as.numeric(BreastCancer$Epith.c.size)
BreastCancer$Bare.nuclei <- as.numeric(BreastCancer$Bare.nuclei)
BreastCancer$Bl.cromatin <- as.numeric(BreastCancer$Bl.cromatin)
BreastCancer$Normal.nucleoli <- as.numeric(BreastCancer$Normal.nucleoli)
BreastCancer$Mitoses <- as.numeric(BreastCancer$Mitoses)
BreastCancer$Id <- NULL
BreastCancer = na.omit(BreastCancer)
bc = cor(BreastCancer[ ,1:9]) #create an object of the features
library(reshape2)
library(ggplot2)
breastcancer.m = melt(BreastCancer, id.var="Class")
ggplot(data=breastcancer.m, aes(x=Class, y=value)) + geom_boxplot() +facet_wrap(~variable,ncol = 3)
#Exercicio 1 - Ficha TP6 Arvores de Decisão
#Ana Madureira
#Pretende-se determinar a qual das duas classes (benigna ou maligna) o tumor pertence:
#  a) Comece por carregar o dataset ”BreastCancer” da biblioteca “mlbench” para o ambiente
# do R. Verifique a sua dimensão e obtenha um sumário dos dados;
library(rpart)
library(mlbench)
# Será utilizado o dataset Wisconsin Breast Cancer
data(BreastCancer)
dim(BreastCancer)
View(BreastCancer)
###[1] 699  11
### levels(BreastCancer$Class)
###[1] "benign"    "malignant"
head(BreastCancer)
summary(BreastCancer)
#b) Usando os gráficos apropriados, analise os vários atributos do conjunto de dados;
library(corrplot)
BreastCancer$Cl.thickness <- as.numeric(BreastCancer$Cl.thickness)
BreastCancer$Cell.size <- as.numeric(BreastCancer$Cell.size)
BreastCancer$Cell.shape <- as.numeric(BreastCancer$Cell.shape)
BreastCancer$Marg.adhesion <- as.numeric(BreastCancer$Marg.adhesion)
BreastCancer$Epith.c.size <- as.numeric(BreastCancer$Epith.c.size)
BreastCancer$Bare.nuclei <- as.numeric(BreastCancer$Bare.nuclei)
BreastCancer$Bl.cromatin <- as.numeric(BreastCancer$Bl.cromatin)
BreastCancer$Normal.nucleoli <- as.numeric(BreastCancer$Normal.nucleoli)
BreastCancer$Mitoses <- as.numeric(BreastCancer$Mitoses)
BreastCancer$Id <- NULL
BreastCancer = na.omit(BreastCancer)
bc = cor(BreastCancer[ ,1:9]) #create an object of the features
library(reshape2)
library(ggplot2)
breastcancer.m = melt(BreastCancer, id.var="Class")
ggplot(data=breastcancer.m, aes(x=Class, y=value)) + geom_boxplot() +facet_wrap(~variable,ncol = 3)
# Libraries
library(PerformanceAnalytics)
library(corrplot)
library(nortest)
library(car)
library(rpart)
library(rpart.plot)
library(neuralnet)
library(FNN)
library(caret)
# Variáveis globais
# Funções
MAE <- function(d) {
mean(abs(d))
}
printMAE <- function(method, d) {
mae <- MAE(d)
cat("(", method, ") MAE: ", mae, "\n")
}
RMSE <- function(d) {
sqrt(mean(d^2))
}
printRMSE <- function(method, d) {
rmse <- RMSE(d)
cat("(", method, ") RMSE: ", rmse, "\n")
}
################################################## REGRESSÃO ##################################################
# Exercício 1 --------------------------------------------------
# Importação dos dados
data <- read.csv("countryaggregatedata.csv")
str(data)
head(data)
# Dimensão
dimension <- dim(data)
numberRows <- dimension[1]
numberColumns <- dimension[2]
cat("Dimensão\nLinhas: ", dimension[1], "\t Colunas: ", dimension[2])
# Sumário
summary(data)
# Normalização os dados
normalize <- function(y) {
(y - min(y)) / (max(y) - min(y))
}
data.normal <- as.data.frame(lapply(data[, 4:numberColumns], normalize))
head(data.normal)
# Exercício 2 --------------------------------------------------
# Matriz de Correlação
chart.Correlation(data[, 4:numberColumns], histogram = TRUE, pch = 19)
# Correlograma (Visualização da Matriz de Correlação)
corrplot(round(cor(data[, 4:numberColumns]), digits = 2), type = "upper", tl.cex = 0.5, tl.col = "black")
# Exercício 3 --------------------------------------------------
# Divisão dos dados em dois subconjuntos - treino e teste - segundo o critério holdout (70% treino / 30% teste)
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, ]
data.test <- data[-index, ]
# Alínea a)
slr.model <- lm(total_deaths ~ new_cases, data = data.train)
slr.model
summary(slr.model)
# Alínea b)
plot(data.train$new_cases, data.train$total_deaths, pch = 20,
xlab = "Novos Casos",
ylab = "Total de Mortes",
main = "Diagrama de Dispersão e Reta de Regressão")
abline(slr.model$coefficients[1], slr.model$coefficients[2], col = "red")
# Alínea c)
slr.pred <- predict(slr.model, data.test)
d <- data.test$total_deaths - slr.pred
# Erro Médio Absoluto (MAE)
printMAE("Regressão Linear Simples", d)
# Raiz Quadrada do Erro Médio (RMSE)
printRMSE("Regressão Linear Simples", d)
# Exercício 4 --------------------------------------------------
# Divisão dos dados em dois subconjuntos - treino e teste - segundo o critério holdout (70% treino / 30% teste)
set.seed(123)
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, 4:numberColumns]
data.test <- data[-index, 4:numberColumns]
# Alínea a)
mlr.model <- lm(life_expectancy ~ ., data = data.train)
mlr.model
summary(mlr.model)
summary(mlr.model)$coefficient
# Previsão (Avaliação do método)
mlr.predict <- predict(mlr.model, data.test)
mlr.predict
mlr.d <- data.test$life_expectancy - mlr.predict
# Erro Médio Absoluto (MAE)
printMAE("Regressão Linear Múltipla", mlr.d);
# Raiz Quadrada do Erro Médio (RMSE)
printRMSE("Regressão Linear Múltipla", mlr.d);
# Alínea b)
# Obtenção da Árvore de Regressão
rpart.model <- rpart(life_expectancy ~ ., method = "anova", data = data.train)
rpart.model
# Visualização da Árvore de Regressão
rpart.plot(rpart.model, digits = 3)
rpart.plot(rpart.model, digits = 4, fallen.leaves = TRUE, type = 3, extra = 101)
# Previsão (Avaliação do método)
rpart.predict <- predict(rpart.model, data.test)
rpart.d <- rpart.predict - data.test$life_expectancy
# Erro Médio Absoluto (MAE)
printMAE("Árvore de Regressão", rpart.d);
# Raiz Quadrada do Erro Médio (RMSE)
printRMSE("Árvore de Regressão", rpart.d);
# Alínea c)
# Divisão dos dados normalizados através do critério holdout (70% treino, 30% teste)
data.train <- data.normal[index, ]
data.test <- data.normal[-index, ]
columnIndex <- which(colnames(data.test) == "life_expectancy")
# Função que cria uma rede neuronal e apresenta o MAE e RMSE
neuralNetwork <- function(hidden) {
neural.model <- neuralnet(life_expectancy ~ ., data = data.train, hidden = hidden)
plot(neural.model)
model.results <- compute(neural.model, data.test[, -columnIndex])
head(model.results$net.result)
neural.predict <- model.results$net.result
head(neural.predict)
correlation <- cor(neural.predict, data.test$life_expectancy)
print(correlation)
# Cálculo do MAE e RMSE
d <- neural.predict - data.test$life_expectancy
# Erro Médio Absoluto (MAE)
printMAE("Árvore de Regressão", d);
# Raiz Quadrada do Erro Médio (RMSE)
printRMSE("Árvore de Regressão", d);
# Retorna os erros das previsões
return(d)
}
neural.d <- neuralNetwork(1) # Rede neuronal com 1 nó interno
neuralNetwork(4) # Rede neuronal com 4 nós internos
neuralNetwork(c(3, 5)) # Rede neuronal com 2 níveis internos de 3 e 5 nós
# Comparação dos resultados obtidos pelos modelos
# Transformação dos erros para valores absolutos (positivos)
mlr.d <- mlr.d^2
rpart.d <- rpart.d^2
neural.d <- neural.d^2
errorsData <- data.frame(
RPart = rpart.d,
Neural = neural.d
)
SerrorsData <- stack(errorsData)
# Testes à normalidade
shapiro.test(rpart.d - neural.d)
lillie.test(rpart.d - neural.d)
# Teste à igualdade das variâncias
leveneTest(SerrorsData[, 1] ~ SerrorsData[, 2])
# Teste comparador das duas médias
t.test(rpart.d, neural.d, var.equal = FALSE, alternative = "two.sided")
################################################## CLASSIFICAÇÃO ##################################################
# Exercício 5 --------------------------------------------------
# Obtenção da média do Rt
rt.average <- mean(data$reproduction_rate)
# Separação do Rt em 0 e 1 (com a média como valor de corte)
split <- function (x) {
if (x > rt.average)  "high"
else  "low"
}
NiveldeRisco <- simplify2array(lapply(data$reproduction_rate, split))
data$NiveldeRisco <- as.factor(NiveldeRisco)
numberColumns <- numberColumns + 1
# Verificação da frequência das duas classes
table(data$NiveldeRisco)
# Exercício 6 --------------------------------------------------
# Variáveis
set.seed(789)
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, 4:numberColumns]
data.test <- data[-index, 4:numberColumns]
accuracy <- function (test, predict) {
m.conf <- table(test, predict)
(m.conf[1, 1] + m.conf[2, 2]) / sum(m.conf)
}
# Alínea a)
# Árvore de Regressão
rpart.model <- rpart(NiveldeRisco ~ ., method = "class", data = data.train)
par(xpd = TRUE)
plot(rpart.model, compress = TRUE)
text(rpart.model, use.n = TRUE)
rpart.plot(rpart.model)
# Previsão
rpart.predict <- predict(rpart.model, data.test, type = "class")
head(rpart.predict)
# Obtenção da Accuracy
rpart.accuracy <- accuracy(as.factor(data.test$NiveldeRisco), rpart.predict)
rpart.accuracy
# Alínea b)
# Adição da ClassedeRisco aos dados normalizados
data.normal$NiveldeRisco <- as.factor(NiveldeRisco)
# Criação de colunas que diferenciam as classes de risco em valores de true/false
data.normal$high <- NiveldeRisco == "high"
data.normal$low <- NiveldeRisco == "low"
# Obtenção de novos dados de treino e teste através dos dados normalizados
data.train <- data.normal[index, ]
data.test <- data.normal[-index, ]
neural.model <- neuralnet(NiveldeRisco ~ ., data = data.train, hidden = 3)
plot(neural.model)
model.results <- compute(neural.model, data.test)
head(model.results$net.result)
neural.predict <- model.results$net.result
head(neural.predict)
idx <- apply(neural.predict, 1, which.max)
predicted <- as.factor(c('high', 'low')[idx])
# Obtenção da Accuracy
neural.accuracy <- accuracy(data.test$NiveldeRisco, predicted)
neural.accuracy
# Alínea c)
columnIndex <- which(colnames(data.train) == "NiveldeRisco")
NiveldeRisco.train <- data.train[, columnIndex]
NiveldeRisco.test <- data.test[, columnIndex]
# Remoção da variável ClassedeRisco
data.train <- data.train[, -columnIndex]
data.test <- data.test[, -columnIndex]
# Obtenção do k através da raiz do número de linhas do treino
k <- round(sqrt(nrow(data.train)))
knn <- knn(train = data.train, test = data.test, cl = NiveldeRisco.train, k = k)
# Obtenção da Accuracy
knn.accuracy <- accuracy(NiveldeRisco.test, knn)
knn.accuracy
# K-fold Cross Validation
nrFolds <- 10
neural.accuracy <- numeric()
knn.accuracy <- numeric()
folds <- rep_len(1:nrFolds, nrow(data))
folds <- sample(folds, length(folds))
for (i in 1:nrFolds) {
fold <- which(folds == i)
data.train <- data.normal[fold, ]
data.test <- data.normal[-fold, ]
# Rede Neuronal
neural.model <- neuralnet(NiveldeRisco ~ ., data = data.train, hidden = 3)
neural.predict <- compute(neural.model, data.test)$net.result
idx <- apply(neural.predict, 1, which.max)
predicted <- as.factor(c('high', 'low')[idx])
neural.accuracy[i] <- accuracy(data.test$NiveldeRisco, predicted)
# Knn
NiveldeRisco.train <- data.train[, columnIndex]
NiveldeRisco.test <- data.test[, columnIndex]
knn <- knn(train = data.train[, -columnIndex], test = data.test[, -columnIndex], cl = NiveldeRisco.train, k = k)
levels(knn) <- c("high", "low")
knn.accuracy[i] <- accuracy(NiveldeRisco.test, knn)
}
print("Rede Neuronal:")
cat(paste("taxa de acerto média: ", 100 * round(mean(neural.accuracy), 4),
"%, desvio : ", round(sd(neural.accuracy), 3)))
print("Knn:")
cat(paste("taxa de acerto média: ", 100 * round(mean(knn.accuracy), 4),
"%, desvio : ", round(sd(knn.accuracy), 3)))
# Comparação dos resultados obtidos pelos modelos
accuracies <- data.frame(
Neural = neural.accuracy,
Knn = knn.accuracy
)
Saccuracies <- stack(accuracies)
# Testes à normalidade
shapiro.test(neural.accuracy - knn.accuracy)
lillie.test(neural.accuracy - knn.accuracy)
# Teste à igualdade das variâncias
leveneTest(Saccuracies[, 1] ~ Saccuracies[, 2])
# Teste comparador das duas médias
t.test(neural.accuracy, knn.accuracy, var.equal = FALSE, alternative = "two.sided")
# Exercício 7 --------------------------------------------------
# Remove a variável criada no exercício 5 e utilizada no exercício 6
data <- subset(data, select = -numberColumns)
numberColumns <- numberColumns - 1
data.normal <- subset(data.normal, select = -c(23, 24, 25))
# Separação do Rt e Incidência em verde, amarelo e vermelho (com base na Matriz de Risco)
ClassedeRisco <- c()
for (i in 1:numberRows) {
incidence <- data[i, "incidence"]
rt <- data[i, "reproduction_rate"]
if (incidence < 120) {
if (rt < 1)  value = "Verde"
else  value = "Amarelo"
} else {
if (rt < 1)  value = "Amarelo"
else  value = "Vermelho"
}
ClassedeRisco <- c(ClassedeRisco, value)
}
data$ClassedeRisco <- as.factor(ClassedeRisco)
numberColumns <- numberColumns + 1
# Verificação da frequência das classes
table(data$ClassedeRisco)
# Exercício 8 --------------------------------------------------
set.seed(456)
index <- sample(1:numberRows, as.integer(0.7 * numberRows))
data.train <- data[index, 4:numberColumns]
data.test <- data[-index, 4:numberColumns]
# Alínea a)
# Árvore de Regressão
rpart.model <- rpart(ClassedeRisco ~ ., method = "class", data = data.train)
par(xpd = TRUE)
plot(rpart.model, compress = TRUE)
text(rpart.model, use.n = TRUE)
rpart.plot(rpart.model)
# Previsão
rpart.predict <- predict(rpart.model, data.test, type = "class")
head(rpart.predict)
# Obtenção dos critérios de avaliação (Accuracy, Sensitivity, Specificity e F1)
confusionMatrix(data.test$ClassedeRisco, rpart.predict)
# Alínea b)
# Adição da ClassedeRisco aos dados normalizados
data.normal$ClassedeRisco <- as.factor(ClassedeRisco)
# Criação de colunas que diferenciam as classes de risco em valores de true/false
data.normal$amarelo <- ClassedeRisco == "Amarelo"
data.normal$verde <- ClassedeRisco == "Verde"
data.normal$vermelho <- ClassedeRisco == "Vermelho"
# Obtenção de novos dados de treino e teste através dos dados normalizados
data.train <- data.normal[index, ]
data.test <- data.normal[-index, ]
neural.model <- neuralnet(ClassedeRisco ~ ., data = data.train, hidden = 3)
plot(neural.model)
model.results <- compute(neural.model, data.test)
head(model.results$net.result)
neural.predict <- model.results$net.result
head(neural.predict)
idx <- apply(neural.predict, 1, which.max)
predicted <- as.factor(c('Amarelo', 'Verde', 'Vermelho')[idx])
confusionMatrix(predicted, data.test$ClassedeRisco)
# Alínea c)
columnIndex <- which(colnames(data.train) == "ClassedeRisco")
ClassedeRisco.train <- data.train[, columnIndex]
ClassedeRisco.test <- data.test[, columnIndex]
# Remoção da variável ClassedeRisco
data.train <- data.train[, -columnIndex]
data.test <- data.test[, -columnIndex]
# Obtenção do k através da raiz do número de linhas do treino
k <- round(sqrt(nrow(data.train)))
knn <- knn(train = data.train, test = data.test, cl = ClassedeRisco.train, k = k)
confusionMatrix(knn, ClassedeRisco.test)
